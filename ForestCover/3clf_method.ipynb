{
 "metadata": {
  "name": "",
  "signature": "sha256:0ad9c8a1cfd839d8f9c16de7e525a80b5a66129282587fbb3783b0e0bc29403e"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Forest Cover Type (2015-01-13): script using 3 classifiers"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this ipynb, we use 3 classifiers to make predictions.  \n",
      "\n",
      "**We have 3 classifiers in total:**\n",
      "1. The first classifier, **`clf_0`**: predicts wheter an instance belongs to class 1 and 2, or it belongs to class 3 to 7.\n",
      "2. For instances belonging to class 1/2, we use the classifier **`clf_12`**, to distinguish between class 1 and class 2.\n",
      "3. For instances belonging to class 3~7, use classifier *`clf_37`**, to tell which class it belongs to."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---------------"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Replace the \"`outfn`\", \"`clf_0`\", \"`clf_12`\" and \"`clf_37`\" below in order to get the corresponding result:**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "outfn = '0113_RF_3step.csv'\n",
      "\n",
      "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier\n",
      "#clf_0 = RandomForestClassifier(n_estimators = 5, n_jobs = -1)\n",
      "#clf_12 = RandomForestClassifier(n_estimators = 5, n_jobs = -1)\n",
      "#clf_37 = RandomForestClassifier(n_estimators = 5, n_jobs = -1)\n",
      "clf_et =  ExtraTreesClassifier(n_estimators=400, criterion='gini', max_depth=None, \n",
      "                        min_samples_split=2, min_samples_leaf=1, max_features='auto', \n",
      "                        bootstrap=False, oob_score=False, n_jobs=-1, verbose=0, \n",
      "                        min_density=None, random_state=0)\n",
      "\n",
      "clf_0 = AdaBoostClassifier(base_estimator=clf_et, n_estimators=300, learning_rate=0.5, algorithm='SAMME', random_state=1)\n",
      "clf_12 = AdaBoostClassifier(base_estimator=clf_et, n_estimators=300, learning_rate=0.5, algorithm='SAMME', random_state=1)\n",
      "clf_37 = AdaBoostClassifier(base_estimator=clf_et, n_estimators=300, learning_rate=0.5, algorithm='SAMME', random_state=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "--------------------------------"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "0. Reading data & defining functions"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "0.1 Reading data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "df_train = pd.read_csv('csv_data/train.csv')\n",
      "df_test = pd.read_csv('csv_data/test.csv')\n",
      "df_train.shape, df_test.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "((15120, 56), (565892, 55))"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The list **\"`feature_cols`\"** is the columns (features) to use when training our clfs. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "feature_cols = [col for col in df_train.columns if col not in ['Cover_Type','Id']] #the attributes to use when predicting"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here we add a boolean attribute:** \"`isClass12`\"**, indicating whether it belongs to first 2 classes or not."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_train['isClass12'] = df_train.Cover_Type<3\n",
      "test_ids = df_test['Id']\n",
      "len(test_ids)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "565892"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "0.2 Defining helper functions"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import cross_val_score, KFold\n",
      "from scipy.stats import sem\n",
      "import numpy as np"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**`cal_CV_score()`**: function to estimate classifier performance by CV"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def cal_CV_score(clf, X, y, K=5, seed=1):\n",
      "    cv = KFold( X.shape[0], K, shuffle=True, random_state = seed )\n",
      "    print 'CV results: ', \n",
      "    scores = cross_val_score(clf, X, y, cv = cv)\n",
      "    print scores    \n",
      "    m = np.mean(scores)\n",
      "    std = sem(scores)\n",
      "    print \"CV score= %f +/- %f\" % (m, std)\n",
      "    return (m, std)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**`train_and_evaluate()`**: train classifier, and calculate CV score of this classifier"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def train_and_evaluate(clf,X, y, K=5, seed=1):\n",
      "    print 'training...',\n",
      "    clf.fit(X, y)\n",
      "    print 'done'\n",
      "    return cal_CV_score(clf, X, y, K, seed)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "--------------------------------"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "1. \"`clf_0`\": classifying whether an instance belongs to first 2 classes"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "1.1 Training `clf_0`"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train0 = df_train[feature_cols]\n",
      "y0 = df_train['isClass12']\n",
      "\n",
      "print 'traing clf_0...'\n",
      "err0 = train_and_evaluate( clf_0, X_train0, y0 )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "traing clf_0...\n",
        "training..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " done\n",
        "CV results: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [ 0.96064815  0.96296296  0.96990741  0.96693122  0.96957672]\n",
        "CV score= 0.966005 +/- 0.001827\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**(Store our classifier:)**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#model_name = 'clf_0.model'\n",
      "#import cPickle as pk\n",
      "#with open(model_name, 'w') as f:\n",
      "  #  pk.dump(clf_0, f)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**(we can later on use the model by:) **"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#with open(model_name) as f:\n",
      " #   clf_0 = pk.load( f )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "1.2 Getting the predicted result (\"`y0_prd`\") by `clf_0`"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_test = df_test[feature_cols]\n",
      "y0_prd = clf_0.predict(X_test)\n",
      "len(y0_prd)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "565892"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**adding `y0_prd` as one column to X_test (so that we can split the test set into 2 subsets):**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_test['isClass12'] = y0_prd # \n",
      "pd.Series(y0_prd).value_counts()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "True     449171\n",
        "False    116721\n",
        "dtype: int64"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "--------------------------------"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "2. \"`clf_12`\": classifying between class 1 and class 2"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "2.1 Training `clf_12`"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_train12 = df_train[ df_train.isClass12 == True ] \n",
      "X_train12 = df_train12[feature_cols]\n",
      "y12 = df_train12['Cover_Type']\n",
      "\n",
      "print 'traing clf_12...'\n",
      "err12 = train_and_evaluate( clf_12, X_train12, y12)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "traing clf_12...\n",
        "training..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " done\n",
        "CV results: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [ 0.83449074  0.84143519  0.81828704  0.84027778  0.83564815]\n",
        "CV score= 0.834028 +/- 0.004151\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**(Saving the `df_train12` , in order to train `clf_12` separately later on:)**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#df_train12.to_csv('train_cls12.csv', index = False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "2.2 Giving predictions (\"`y12_prd`\") for test set"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_test12 = df_test[ df_test.isClass12 == True ] # instances to be classified by `clf_0` as belong to class 1/2\n",
      "X_test12 = df_test12[feature_cols]\n",
      "y12_prd = clf_12.predict(X_test12)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pd.Series(y12_prd).value_counts()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "2    238830\n",
        "1    210341\n",
        "dtype: int64"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "--------------------------------"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "3. \"`clf_37`\": classifying class 3~7"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "3.1 Training `clf_37`"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_train37 = df_train[ df_train.isClass12 == False ] \n",
      "X_train37 = df_train37[feature_cols]\n",
      "y37 = df_train37['Cover_Type']\n",
      "\n",
      "print 'traing clf_37...'\n",
      "err37 = train_and_evaluate( clf_37, X_train37, y37)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "traing clf_37...\n",
        "training..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " done\n",
        "CV results: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [ 0.94537037  0.93888889  0.94814815  0.93611111  0.94722222]\n",
        "CV score= 0.943148 +/- 0.002390\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#df_train37.to_csv('train_cls37.csv', index = False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "3.2 Giving predictions (\"`y37_prd`\") for test set"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_test37 = df_test[ df_test.isClass12 == False ] \n",
      "X_test37 = df_test37[feature_cols]\n",
      "y37_prd = clf_37.predict(X_test37)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pd.Series(y37_prd).value_counts()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 23,
       "text": [
        "3    37285\n",
        "7    27418\n",
        "5    26187\n",
        "6    23809\n",
        "4     2022\n",
        "dtype: int64"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print len(y12_prd)+len(y37_prd), len(df_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "565892 565892\n"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "--------------------------------"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "4. Putting results \"`y12_prd`\" and \"`y37_prd`\" together"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "res12 = pd.DataFrame(df_test12.Id)\n",
      "res12['Cover_Type'] = y12_prd\n",
      "res37 = pd.DataFrame(df_test37.Id)\n",
      "res37['Cover_Type'] = y37_prd\n",
      "\n",
      "res_all = pd.concat([res12, res37])\n",
      "print len(res_all)\n",
      "\n",
      "res_all.to_csv(outfn, index=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "565892\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'error for clf_0: %.4f +/- %.4f' % err0\n",
      "print 'error for clf_12: %.4f +/- %.4f' % err12\n",
      "print 'error for clf_37: %.4f +/- %.4f' % err37\n",
      "\n",
      "y0_ratio = pd.Series(y0_prd).value_counts()[1]*1./len(y0_prd) #ratio of instances classified by\n",
      "print 'y0_prd ratio is: %.4f' % y0_ratio\n",
      "\n",
      "err_est =  err0[0]*( y0_ratio*err12[0] + (1-y0_ratio)*err37[0] )\n",
      "print 'so the estimated score is %.4f' % err_est"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "error for clf_0: 0.9660 +/- 0.0018\n",
        "error for clf_12: 0.8340 +/- 0.0042\n",
        "error for clf_37: 0.9431 +/- 0.0024\n",
        "y0_prd ratio is: 0.7937\n",
        "so the estimated score is 0.8274\n"
       ]
      }
     ],
     "prompt_number": 35
    }
   ],
   "metadata": {}
  }
 ]
}