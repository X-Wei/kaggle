{
 "metadata": {
  "name": "",
  "signature": "sha256:b76a261623db74764cac78fe503d9ab1574407ba22711642dde7a097f5ca9257"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Forest Cover Type (2015-01-13): script with one classifier"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this ipynb, we use one clissifier (`clf`) to predict the cover type, and give the result."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%cd /media/SD4GB/Kaggle"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/media/SD4GB/Kaggle\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Change the `clf` below in order to get different result:**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
      "##clf_1: boost ExtrTree\n",
      "clf_et =  ExtraTreesClassifier(n_estimators=400, criterion='gini', max_depth=None, \n",
      "                        min_samples_split=2, min_samples_leaf=1, max_features='auto', \n",
      "                        bootstrap=False, oob_score=False, n_jobs=-1, verbose=0, \n",
      "                        min_density=None, random_state=0)\n",
      "clf_adaEt = AdaBoostClassifier(base_estimator=clf_et, n_estimators=10, learning_rate=0.5, \n",
      "                        algorithm='SAMME', random_state=1)\n",
      "\n",
      "##clf2: boost RandTree\n",
      "clf_rf = RandomForestClassifier(n_estimators=100, criterion='gini', max_depth=None, \n",
      "                        min_samples_split=2, min_samples_leaf=1, max_features='auto', \n",
      "                        bootstrap=False, oob_score=False, n_jobs=-1, verbose=0, \n",
      "                        min_density=None, random_state=0)\n",
      "clf_adaRF = AdaBoostClassifier(base_estimator=clf_rf, n_estimators=300, learning_rate=0.5, \n",
      "                        algorithm='SAMME', random_state=1)\n",
      "\n",
      "\n",
      "##clf3: GBC\n",
      "clf_gbc = GradientBoostingClassifier(n_estimators=500,random_state=0)\n",
      "\n",
      "\n",
      "#########\n",
      "clf = clf_rf\n",
      "\n",
      "### class weights \n",
      "#cw = [219139, 241532, 36550, 1828, 20374, 21061, 25408] #class weights\n",
      "#cw = [2191, 2415,  365,   18,  203,  210,  254]\n",
      "cw = [ 2.19139,  2.41532,  0.3655 ,  0.01828,  0.20374,  0.21061,  0.25408]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Change `train_fn`,`test_fn` and `out_fn` below to specify input/output file names:**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_fn = 'FEs/train_FE2.csv'\n",
      "test_fn = 'FEs/test_FE2.csv'\n",
      "\n",
      "out_fn = '0120_1step_RF100_prdWeighted_FE2.csv'\n",
      "output = True\n",
      "\n",
      "cal_CV = False\n",
      "K=5"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "-------"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "0. Reading the data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "df_train = pd.read_csv(train_fn)\n",
      "df_test = pd.read_csv(test_fn)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_train.shape, df_test.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "((15120, 68), (565892, 67))"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "feature_cols = [col for col in df_train.columns if col not in ['Cover_Type','Id']]\n",
      "X_train = df_train[feature_cols]\n",
      "X_test = df_test[feature_cols]\n",
      "y = df_train['Cover_Type'] # the class to classify at last\n",
      "test_ids = df_test['Id']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y.value_counts()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "7    2160\n",
        "6    2160\n",
        "5    2160\n",
        "4    2160\n",
        "3    2160\n",
        "2    2160\n",
        "1    2160\n",
        "dtype: int64"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "1. Training the classifier"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sw = [ cw[c-1] for c in y]\n",
      "import numpy as np\n",
      "sw = np.array(sw)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf.fit(X_train, y)#, sample_weight=sw"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "RandomForestClassifier(bootstrap=False, compute_importances=None,\n",
        "            criterion='gini', max_depth=None, max_features='auto',\n",
        "            max_leaf_nodes=None, min_density=None, min_samples_leaf=1,\n",
        "            min_samples_split=2, n_estimators=100, n_jobs=-1,\n",
        "            oob_score=False, random_state=0, verbose=0)"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "2. Using CV to estimate our classifier"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "if cal_CV == True:\n",
      "    from sklearn.cross_validation import cross_val_score, KFold\n",
      "    cv5 = KFold( X_train.shape[0], K, shuffle=True, random_state = 1 )\n",
      "    scores = cross_val_score(clf, X_train, y, cv = cv5)\n",
      "    print scores\n",
      "    from scipy.stats import sem\n",
      "    import numpy as np\n",
      "    print \"CV score: %.4f +/- %.4f\" % (np.mean(scores), sem(scores))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "3. Giving predictions to X_test, and giving the output file"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "We try to weight the predictions of all trees in the trained random forest:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_all_predictions(rf_clf, X_test, cw):\n",
      "    'giving predictions weighted by cw '\n",
      "    all_res = pd.DataFrame()\n",
      "    i=1\n",
      "    \n",
      "    for est in rf_clf.estimators_:\n",
      "        resi = est.predict(X_test) # predictions are 0~6!!\n",
      "        all_res[str(i)] = resi\n",
      "        i += 1\n",
      "    return all_res"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def weighted_prd(row):\n",
      "    count, division = np.histogram(row,bins=7)\n",
      "    count_weighted = np.array( [ count[i]*sw[i] for i in range(7) ] )\n",
      "    return count_weighted.argmax()+1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Output our results"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "if output==True:\n",
      "    #prd = clf.predict(X_test)\n",
      "    \n",
      "    #only for RandForest: weight predictions\n",
      "    all_prd = get_all_predictions(clf, X_test, cw) \n",
      "    prd = all_prd.apply(weighted_prd, axis = 1)\n",
      "    \n",
      "    df_out = pd.DataFrame(test_ids)\n",
      "    df_out['Cover_Type'] = prd\n",
      "    df_out.to_csv( out_fn, index=False )\n",
      "    df_out.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    }
   ],
   "metadata": {}
  }
 ]
}